# Interlingua (USR) based machine translation for Indian languages
_This repository contains the code and related files, from the work I did at the Language Technologies Research Centre(LTRC), IIIT Hyderabad as a research intern under the guidance of Dr. Sukhada(IIT BHU) and Dr. Soma Paul (IIIT-H)._

Indian languages are syntactically and morphologically complex, in addition to them being low resource. The objective of the project is to create effective methods for neural machine translation with limited resources. This can be achieved by combining developments in deep learning combined with heuristics from traditional linguistic and grammatical knowledge. 

The main focus is to design an interlingua(USR, Universal Semantic Representation), based on the Pāṇinian Sanskrit grammatical framework, which will serve as a comprehensible intermediary representation for all the languages included in the translation process. We focused on Hindi, Sanskrit and English(for proof of concept) as part of our experiments.

My undertakings can be broadly categorized into the following:

### Dataset creation and processing:

**Concept dictionary creation**: Hindi and Sanskrit bilingual dictionaries from various sources([1](https://dsal.uchicago.edu/dictionaries/mcgregor/),[2](https://www.sanskrit-lexicon.uni-koeln.de/),[3](https://sanskrit.inria.fr/DICO/index.en.html)) were scraped to build a [concept dictionary repository](https://github.com/adiparashar/LTRC/tree/main/generated%20data/concept_dicts). These concept dictionaries map Hindi & Sanskrit words to their concepts(single or compund word meanings in a common language, say English) and the [generated](http://sweaglesw.org/linguistics/ace/) Minimum Recursion Semantics(MRS) features. 

**USR generation**: Universal Semantic Representation (USR) captures the meaning expressed by a sentence in the discourse. It has rows corresponding to properties of the sentence and its concept words. These properties are the concepts(and TAM (tense-aspect-modality) specification on the verb), semantic category of nouns, GNP (Gender, Number, Person) information, dependency relations, anaphora,speaker’s view-points, sentence type etc. The USR acts as the interlingua in our translation process. [These](https://github.com/adiparashar/LTRC/tree/main/generated%20data/USR) are generated by following the heuristics from the Pāṇinian Sanskrit grammatical framework.


### Sentence generation:

**Neural generation**: To generate the sentence back from a given USR two kinds of approaches were followed, namely the hybrid and the direct approach depending on the proportion of deep learning and linguistics they invloved. 
* The hybrid approach used a linguistic rule-based approach to generate the sentences. Since the USRs did not have [postposition](https://hindilanguage.info/hindi-grammar/postpositions/) related details, so these generated sentences were often devoid of/contained incorrect postpositions. To generate sentences with the postpositions, LLMs were finetuned on the [mask prediction task](https://github.com/adiparashar/LTRC/tree/main/postposition%20prediction) for Hindi sentences, where the masks were the unknown postpositions.

* The [direct approach](https://github.com/adiparashar/LTRC/tree/main/USR%20to%20sentence) involved converting the USRs into graphs, with hybrid rules from Abstract Meaning Representation(AMR), Universal Networking Language(UNL) frameworks. These USR graphs were then linearized using a depth first search(DFS) based approach, to get sequences. We finetuned different seq2seq LLMs like BART and mT5 to generate the sentences back from these USR linearizations. BART was chosen because of it's [denoising training objective](https://hindilanguage.info/hindi-grammar/postpositions/), which could help in getting the sentences from the linearizations. 

